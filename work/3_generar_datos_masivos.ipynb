{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae964e9f-ddc2-40b7-816a-e86a1a37ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO GENERACIÓN MASIVA DE DATOS (CON LIMPIEZA) ---\n",
      "⚠️ Advertencia registrando driver: An error occurred while calling z:java.lang.Class.forName.\n",
      ": java.lang.ClassNotFoundException: com.microsoft.sqlserver.jdbc.SQLServerDriver\n",
      "\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n",
      "\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n",
      "\tat java.base/java.lang.Class.forName0(Native Method)\n",
      "\tat java.base/java.lang.Class.forName(Class.java:375)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "\n",
      ">>> 1. Limpiando datos antiguos...\n",
      "   ❌ Error SQL: An error occurred while calling z:java.sql.DriverManager.getConnection.\n",
      ": java.sql.SQLException: No suitable driver found for jdbc:sqlserver://sql_server:1433;databaseName=alquiler_habitacion;encrypt=true;trustServerCertificate=true;\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:229)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "   ❌ Error SQL: An error occurred while calling z:java.sql.DriverManager.getConnection.\n",
      ": java.sql.SQLException: No suitable driver found for jdbc:sqlserver://sql_server:1433;databaseName=alquiler_habitacion;encrypt=true;trustServerCertificate=true;\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:229)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "   ❌ Error SQL: An error occurred while calling z:java.sql.DriverManager.getConnection.\n",
      ": java.sql.SQLException: No suitable driver found for jdbc:sqlserver://sql_server:1433;databaseName=alquiler_habitacion;encrypt=true;trustServerCertificate=true;\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:229)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "   ❌ Error SQL: An error occurred while calling z:java.sql.DriverManager.getConnection.\n",
      ": java.sql.SQLException: No suitable driver found for jdbc:sqlserver://sql_server:1433;databaseName=alquiler_habitacion;encrypt=true;trustServerCertificate=true;\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)\n",
      "\tat java.sql/java.sql.DriverManager.getConnection(DriverManager.java:229)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "\n",
      ">>> 2. Verificando Propietario...\n",
      "   ✨ No hay propietarios. Creando Propietario Único...\n",
      "   -> Insertando lotes en PROPIETARIO...\n",
      "\n",
      ">>> 3. Generando 50 habitaciones...\n",
      "   -> Insertando lotes en HABITACION...\n",
      "\n",
      ">>> 4. Generando 500 clientes...\n",
      "   -> Insertando lotes en CLIENTE...\n",
      "\n",
      ">>> 5. Preparando 2000 contratos...\n",
      "   -> Insertando lotes en CONTRATO...\n",
      "\n",
      ">>> 6. Generando pagos históricos...\n",
      "   -> Insertando 10796 pagos...\n",
      "   -> Insertando lotes en PAGO...\n",
      "\n",
      "✅ ¡Base de datos regenerada correctamente!\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalamos la librería Faker (si no está)\n",
    "!pip install faker -q\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "CANTIDAD_CLIENTES = 500\n",
    "CANTIDAD_HABITACIONES = 50\n",
    "CANTIDAD_CONTRATOS = 2000 \n",
    "fake = Faker('es_ES')\n",
    "\n",
    "# Configuración de Conexión\n",
    "DB_HOST = \"sql_server\"\n",
    "DB_PORT = \"1433\"\n",
    "DB_USER = \"sa\"\n",
    "DB_PASS = \"PasswordFuerte123!\" \n",
    "DRIVER_PKG = \"com.microsoft.sqlserver:mssql-jdbc:11.2.0.jre8\"\n",
    "DRIVER_CLASS = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "DB_NAME = \"alquiler_habitacion\"\n",
    "\n",
    "print(\"--- INICIANDO GENERACIÓN MASIVA DE DATOS (CON LIMPIEZA) ---\")\n",
    "\n",
    "# Iniciar Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeneradorDatosMasivos\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", DRIVER_PKG) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# --- CORRECCIÓN CRÍTICA: REGISTRAR DRIVER MANUALMENTE ---\n",
    "# Esto hace que 'DriverManager' encuentre el driver para los DELETE\n",
    "try:\n",
    "    spark.sparkContext._gateway.jvm.java.lang.Class.forName(DRIVER_CLASS)\n",
    "    print(\"✅ Driver JDBC registrado en la JVM para comandos SQL puros.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Advertencia registrando driver: {e}\")\n",
    "\n",
    "# 1. Función para ejecutar SQL Puro (DELETE, UPDATE, etc.)\n",
    "def ejecutar_sql_puro(query):\n",
    "    url = f\"jdbc:sqlserver://{DB_HOST}:{DB_PORT};databaseName={DB_NAME};encrypt=true;trustServerCertificate=true;\"\n",
    "    try:\n",
    "        manager = spark.sparkContext._gateway.jvm.java.sql.DriverManager\n",
    "        con = manager.getConnection(url, DB_USER, DB_PASS)\n",
    "        stmt = con.createStatement()\n",
    "        stmt.execute(query)\n",
    "        stmt.close()\n",
    "        con.close()\n",
    "        print(f\"   ✅ Ejecutado: {query}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error SQL: {e}\")\n",
    "\n",
    "# 2. Función auxiliar para escribir DataFrames\n",
    "def guardar_en_sql(df, tabla):\n",
    "    url = f\"jdbc:sqlserver://{DB_HOST}:{DB_PORT};databaseName={DB_NAME};encrypt=true;trustServerCertificate=true;\"\n",
    "    print(f\"   -> Insertando lotes en {tabla}...\")\n",
    "    df.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", url) \\\n",
    "        .option(\"dbtable\", tabla) \\\n",
    "        .option(\"user\", DB_USER) \\\n",
    "        .option(\"password\", DB_PASS) \\\n",
    "        .option(\"driver\", DRIVER_CLASS) \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "\n",
    "# --- A. LIMPIEZA DE DATOS (Orden inverso para FKs) ---\n",
    "print(\"\\n>>> 1. Limpiando datos antiguos...\")\n",
    "ejecutar_sql_puro(\"DELETE FROM PAGO\")\n",
    "ejecutar_sql_puro(\"DELETE FROM CONTRATO\")\n",
    "ejecutar_sql_puro(\"DELETE FROM CLIENTE\")\n",
    "ejecutar_sql_puro(\"DELETE FROM HABITACION\")\n",
    "# PROPIETARIO no se borra para mantener el ID único si ya existe\n",
    "\n",
    "# --- B. GESTIÓN DE PROPIETARIO ÚNICO ---\n",
    "print(\"\\n>>> 2. Verificando Propietario...\")\n",
    "\n",
    "url_read = f\"jdbc:sqlserver://{DB_HOST}:{DB_PORT};databaseName={DB_NAME};encrypt=true;trustServerCertificate=true;\"\n",
    "try:\n",
    "    df_props_existentes = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", url_read).option(\"dbtable\", \"PROPIETARIO\") \\\n",
    "        .option(\"user\", DB_USER).option(\"password\", DB_PASS).option(\"driver\", DRIVER_CLASS) \\\n",
    "        .load()\n",
    "    count_props = df_props_existentes.count()\n",
    "except:\n",
    "    count_props = 0\n",
    "\n",
    "if count_props > 0:\n",
    "    print(f\"   ℹ️ Ya existen {count_props} propietario(s). Usaremos el existente.\")\n",
    "else:\n",
    "    print(\"   ✨ No hay propietarios. Creando Propietario Único...\")\n",
    "    propietarios = [(\n",
    "        str(random.randint(10000000, 99999999)),\n",
    "        \"Juan Dueño Único\", \n",
    "        fake.phone_number()[:20],\n",
    "        fake.email()\n",
    "    )]\n",
    "    schema_prop = StructType([\n",
    "        StructField(\"dniPropietario\", StringType(), True),\n",
    "        StructField(\"nombrePropietario\", StringType(), True),\n",
    "        StructField(\"celularPropietario\", StringType(), True),\n",
    "        StructField(\"correoPropietario\", StringType(), True)\n",
    "    ])\n",
    "    df_prop = spark.createDataFrame(propietarios, schema=schema_prop)\n",
    "    guardar_en_sql(df_prop, \"PROPIETARIO\")\n",
    "\n",
    "\n",
    "# --- C. GENERAR HABITACIONES ---\n",
    "print(f\"\\n>>> 3. Generando {CANTIDAD_HABITACIONES} habitaciones...\")\n",
    "tipos = ['Simple', 'Doble', 'Matrimonial', 'Suite', 'Penthouse']\n",
    "habitaciones = []\n",
    "for i in range(1, CANTIDAD_HABITACIONES + 1):\n",
    "    numero = f\"{random.randint(1, 10)}{random.randint(0, 9):02d}\"\n",
    "    habitaciones.append((\n",
    "        numero, \n",
    "        random.choice(tipos), \n",
    "        float(random.choice([400, 500, 800])),\n",
    "        'Disponible', \n",
    "        random.choice(['Wifi', 'Wifi, TV', 'Full'])\n",
    "    ))\n",
    "\n",
    "schema_hab = StructType([\n",
    "    StructField(\"numeroHabitacion\", StringType(), True),\n",
    "    StructField(\"tipoHabitacion\", StringType(), True),\n",
    "    StructField(\"precioMensual\", DoubleType(), True),\n",
    "    StructField(\"estado\", StringType(), True),\n",
    "    StructField(\"serviciosIncluidos\", StringType(), True)\n",
    "])\n",
    "df_hab = spark.createDataFrame(habitaciones, schema=schema_hab)\n",
    "guardar_en_sql(df_hab, \"HABITACION\")\n",
    "\n",
    "\n",
    "# --- D. GENERAR CLIENTES ---\n",
    "print(f\"\\n>>> 4. Generando {CANTIDAD_CLIENTES} clientes...\")\n",
    "clientes = []\n",
    "for _ in range(CANTIDAD_CLIENTES):\n",
    "    clientes.append((\n",
    "        fake.name(), \n",
    "        str(random.randint(10000000, 99999999)),\n",
    "        fake.phone_number()[:20],\n",
    "        fake.email(),\n",
    "        fake.address()[:200]\n",
    "    ))\n",
    "\n",
    "schema_cli = StructType([\n",
    "    StructField(\"nombreCli\", StringType(), True),\n",
    "    StructField(\"dniCli\", StringType(), True),\n",
    "    StructField(\"telefonoCli\", StringType(), True),\n",
    "    StructField(\"correoCli\", StringType(), True),\n",
    "    StructField(\"direccionCli\", StringType(), True)\n",
    "])\n",
    "df_cli = spark.createDataFrame(clientes, schema=schema_cli)\n",
    "guardar_en_sql(df_cli, \"CLIENTE\")\n",
    "\n",
    "\n",
    "# --- E. GENERAR CONTRATOS ---\n",
    "print(f\"\\n>>> 5. Preparando {CANTIDAD_CONTRATOS} contratos...\")\n",
    "\n",
    "# Recuperamos IDs reales\n",
    "def obtener_ids(tabla, columna):\n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", url_read).option(\"dbtable\", tabla).option(\"user\", DB_USER).option(\"password\", DB_PASS).option(\"driver\", DRIVER_CLASS).load()\n",
    "    return [row[0] for row in df.select(columna).collect()]\n",
    "\n",
    "ids_clientes = obtener_ids(\"CLIENTE\", \"idCliente\")\n",
    "ids_habitaciones = obtener_ids(\"HABITACION\", \"idHabitacion\")\n",
    "ids_propietarios = obtener_ids(\"PROPIETARIO\", \"idPropietario\")\n",
    "\n",
    "if not ids_propietarios:\n",
    "    raise Exception(\"❌ ERROR: No se encontró el ID del propietario. Algo falló en el paso 2.\")\n",
    "\n",
    "id_prop_unico = ids_propietarios[0]\n",
    "\n",
    "contratos = []\n",
    "fecha_base = datetime.now() - timedelta(days=730)\n",
    "\n",
    "for _ in range(CANTIDAD_CONTRATOS):\n",
    "    fecha_inicio = fecha_base + timedelta(days=random.randint(0, 700))\n",
    "    monto = float(random.choice([400, 500, 600, 850, 1200]))\n",
    "    \n",
    "    contratos.append((\n",
    "        fecha_inicio.date(),\n",
    "        None, \n",
    "        monto,\n",
    "        int(random.choice(ids_clientes)),\n",
    "        int(random.choice(ids_habitaciones)),\n",
    "        int(id_prop_unico), # Todos los contratos van al mismo propietario\n",
    "        'Activo'\n",
    "    ))\n",
    "\n",
    "schema_contrato = StructType([\n",
    "    StructField(\"fechaInicio\", DateType(), True),\n",
    "    StructField(\"fechaFin\", DateType(), True),\n",
    "    StructField(\"montoTotal\", DoubleType(), True),\n",
    "    StructField(\"idCliente\", IntegerType(), True),\n",
    "    StructField(\"idHabitacion\", IntegerType(), True),\n",
    "    StructField(\"idPropietario\", IntegerType(), True),\n",
    "    StructField(\"EstadoContrato\", StringType(), True)\n",
    "])\n",
    "df_contratos = spark.createDataFrame(contratos, schema=schema_contrato)\n",
    "guardar_en_sql(df_contratos, \"CONTRATO\")\n",
    "\n",
    "\n",
    "# --- F. GENERAR PAGOS ---\n",
    "print(\"\\n>>> 6. Generando pagos históricos...\")\n",
    "\n",
    "# Leemos los contratos recién insertados\n",
    "df_contratos_reales = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", url_read).option(\"dbtable\", \"CONTRATO\") \\\n",
    "    .option(\"user\", DB_USER).option(\"password\", DB_PASS).option(\"driver\", DRIVER_CLASS) \\\n",
    "    .load() \\\n",
    "    .select(\"idContrato\", \"fechaInicio\", \"montoTotal\").collect()\n",
    "\n",
    "pagos = []\n",
    "for row in df_contratos_reales:\n",
    "    id_contrato = row['idContrato']\n",
    "    fecha_inicio = row['fechaInicio']\n",
    "    monto = row['montoTotal']\n",
    "    \n",
    "    cant_pagos = random.randint(1, 12)\n",
    "    for p in range(cant_pagos):\n",
    "        if isinstance(fecha_inicio, datetime):\n",
    "            f_pago = fecha_inicio + timedelta(days=30 * (p+1))\n",
    "        else:\n",
    "            f_pago = datetime.combine(fecha_inicio, datetime.min.time()) + timedelta(days=30 * (p+1))\n",
    "            \n",
    "        if f_pago > datetime.now(): break\n",
    "        \n",
    "        pagos.append((\n",
    "            f_pago.date(),\n",
    "            float(monto),\n",
    "            random.choice(['Yape', 'Efectivo', 'Transferencia']),\n",
    "            int(id_contrato)\n",
    "        ))\n",
    "\n",
    "print(f\"   -> Insertando {len(pagos)} pagos...\")\n",
    "schema_pago = StructType([\n",
    "    StructField(\"fechaPago\", DateType(), True),\n",
    "    StructField(\"montoPago\", DoubleType(), True),\n",
    "    StructField(\"metodoPago\", StringType(), True),\n",
    "    StructField(\"idContrato\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Batch processing para evitar saturar memoria\n",
    "if pagos:\n",
    "    df_pagos = spark.createDataFrame(pagos, schema=schema_pago)\n",
    "    guardar_en_sql(df_pagos, \"PAGO\")\n",
    "else:\n",
    "    print(\"   ⚠️ No se generaron pagos (revisar fechas).\")\n",
    "\n",
    "print(\"\\n✅ ¡Base de datos regenerada correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41f531-e65c-4498-98c6-e8568f5fb300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
